{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9915b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f689f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de palabras con su polaridad (-1 a +1)\n",
    "polaridad = {\n",
    "    \"bueno\": 1.0,\n",
    "    \"excelente\": 1.0,\n",
    "    \"malo\": -1.0,\n",
    "    \"horrible\": -1.0,\n",
    "    \"gusta\": 0.8,\n",
    "    \"encanta\": 1.0,\n",
    "    \"odio\": -1.0,\n",
    "    \"terrible\": -1.0,\n",
    "    \"desastre\": -1.0,\n",
    "    \"no\": -0.5,\n",
    "    \"nunca\": -0.5,\n",
    "    \"siempre\": 0.5,\n",
    "    \"fantástico\": 1.0,\n",
    "    \"horrendo\": -1.0\n",
    "}\n",
    "\n",
    "# Intensificadores y atenuadores\n",
    "intensificadores = {\n",
    "    \"muy\": 1.5,\n",
    "    \"bastante\": 1.3,\n",
    "    \"sumamente\": 1.7\n",
    "}\n",
    "\n",
    "atenuadores = {\n",
    "    \"algo\": 0.7,\n",
    "    \"un_poco\": 0.5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47abe830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimiento_token(token):\n",
    "    \"\"\"\n",
    "    Calcula la polaridad de un token según su contexto gramatical.\n",
    "    \"\"\"\n",
    "    base = polaridad.get(token.lemma_, 0)\n",
    "    if base == 0:\n",
    "        return 0\n",
    "\n",
    "    # Ajuste por negación\n",
    "    for hijo in token.children:\n",
    "        if hijo.dep_ == \"neg\":\n",
    "            base *= -1\n",
    "\n",
    "    # Ajuste por modificadores adverbiales (intensificadores o atenuadores)\n",
    "    for hijo in token.children:\n",
    "        if hijo.dep_ == \"advmod\":\n",
    "            if hijo.lemma_ in intensificadores:\n",
    "                base *= intensificadores[hijo.lemma_]\n",
    "            elif hijo.lemma_ in atenuadores:\n",
    "                base *= atenuadores[hijo.lemma_]\n",
    "\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e939491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_sentimiento(texto):\n",
    "    doc = nlp(texto)\n",
    "    polaridades = []\n",
    "    \n",
    "    for sent in doc.sents:  # Recorremos cada oración\n",
    "        total = 0\n",
    "        count = 0\n",
    "        \n",
    "        for token in sent:\n",
    "            p = sentimiento_token(token)\n",
    "            if p != 0:\n",
    "                total += p\n",
    "                count += 1\n",
    "        \n",
    "        # Promedio de sentimiento en la oración\n",
    "        if count > 0:\n",
    "            polaridad_media = total / count\n",
    "        else:\n",
    "            polaridad_media = 0\n",
    "\n",
    "        # Si la oración tiene \"pero\", ponderamos la parte posterior\n",
    "        if any(tok.text.lower() == \"pero\" for tok in sent):\n",
    "            polaridad_media *= 1.2  # damos más peso a lo posterior\n",
    "\n",
    "        polaridades.append(polaridad_media)\n",
    "    \n",
    "    # Composición global del texto\n",
    "    if len(polaridades) > 0:\n",
    "        global_sentimiento = sum(polaridades) / len(polaridades)\n",
    "    else:\n",
    "        global_sentimiento = 0\n",
    "    \n",
    "    # Clasificación final\n",
    "    if global_sentimiento > 0.25:\n",
    "        etiqueta = \"Positivo\"\n",
    "    elif global_sentimiento < -0.25:\n",
    "        etiqueta = \"Negativo\"\n",
    "    else:\n",
    "        etiqueta = \"Neutro\"\n",
    "\n",
    "    return {\n",
    "        \"sentimiento_global\": round(global_sentimiento, 2),\n",
    "        \"etiqueta\": etiqueta,\n",
    "        \"detalles\": polaridades\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c22ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentimiento_global': -0.6, 'etiqueta': 'Negativo', 'detalles': [-0.6]}\n"
     ]
    }
   ],
   "source": [
    "texto = \"No me gusta el servicio, pero la comida está muy buena.\"\n",
    "resultado = analizar_sentimiento(texto)\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3127f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"53eaa25521204f8e8568762189175e5e-0\" class=\"displacy\" width=\"1975\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">No</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">me</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">gusta</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">el</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">servicio,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">pero</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">comida</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">está</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">muy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">buena.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,264.5 385.0,264.5 385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">iobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-3\" stroke-width=\"2px\" d=\"M420,439.5 C420,264.5 735.0,264.5 735.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,441.5 L743.0,429.5 727.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-4\" stroke-width=\"2px\" d=\"M945,439.5 C945,89.5 1795.0,89.5 1795.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-5\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-6\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,177.0 1790.0,177.0 1790.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,264.5 1785.0,264.5 1785.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-53eaa25521204f8e8568762189175e5e-0-9\" stroke-width=\"2px\" d=\"M420,439.5 C420,2.0 1800.0,2.0 1800.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-53eaa25521204f8e8568762189175e5e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,441.5 L1808.0,429.5 1792.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Renderizar con displacy sin depender de IPython.display.display (que falta)\n",
    "from spacy import displacy\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_md')\n",
    "doc = nlp(\"No me gusta el servicio, pero la comida está muy buena.\")\n",
    "# Generar HTML con displacy\n",
    "html = displacy.render(doc, style='dep', jupyter=False)\n",
    "\n",
    "# Intentar usar display_html (presente en IPython.core.display en esta venv)\n",
    "try:\n",
    "    from IPython.core import display as ipd\n",
    "    ipd.display_html(html, raw=True)\n",
    "except Exception as e:\n",
    "    # Fallback: escribir a archivo para abrir en el navegador\n",
    "    with open('displacy_output.html', 'w', encoding='utf8') as f:\n",
    "        f.write(html)\n",
    "        print('No se pudo mostrar en el notebook:', e)\n",
    "        print(\"Se ha escrito 'displacy_output.html' en el directorio de trabajo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3168b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "# Ejemplo de diccionario (asegúrate de usar lemas en minúsculas)\n",
    "polaridad = {\n",
    "    \"bueno\": 1.0,\n",
    "    \"excelente\": 1.0,\n",
    "    \"malo\": -1.0,\n",
    "    \"horrible\": -1.0,\n",
    "    \"gustar\": 0.8,\n",
    "    \"encantar\": 1.0,\n",
    "    \"odiar\": -1.0,\n",
    "    \"terrible\": -1.0,\n",
    "    \"desastre\": -1.0,\n",
    "    # \"no\": -0.5,\n",
    "    # \"nunca\": -0.5,\n",
    "    # \"siempre\": 0.5,\n",
    "    # \"fantástico\": 1.0,\n",
    "    # \"horrendo\": -1.0\n",
    "}\n",
    "\n",
    "intensificadores = {\"muy\": 1.5, \"bastante\": 1.3, \"sumamente\": 1.7}\n",
    "atenuadores = {\"algo\": 0.7, \"un_poco\": 0.5, \"poco\": 0.6}\n",
    "\n",
    "def _lookup_lemma_polarity(token):\n",
    "    \"\"\"Buscar polaridad exacta por lema (minúscula).\"\"\"\n",
    "    return polaridad.get(token.lemma_.lower(), 0.0)\n",
    "\n",
    "def _search_subtree_polarity(token, max_depth=2, visited=None):\n",
    "    \"\"\"\n",
    "    Busca polaridad en token, sus hijos y (si aplica) nietos hasta max_depth.\n",
    "    Devuelve (polaridad, fuente_token) o (0, None).\n",
    "    \"\"\"\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if (token.i, token.sent.start) in visited:\n",
    "        return 0.0, None\n",
    "    visited.add((token.i, token.sent.start))\n",
    "\n",
    "    p = _lookup_lemma_polarity(token)\n",
    "    if p != 0.0:\n",
    "        return p, token\n",
    "\n",
    "    if max_depth <= 0:\n",
    "        return 0.0, None\n",
    "\n",
    "    # Priorizar adjetivos que modifican sustantivos (amod), complementos, objetos\n",
    "    for child in token.children:\n",
    "        # Buscar adjetivos que califican (amod), o complementos (xcomp, ccomp, obj)\n",
    "        if child.dep_ in {\"amod\", \"advmod\", \"xcomp\", \"ccomp\", \"obj\", \"iobj\", \"acomp\"}:\n",
    "            p_child, src = _search_subtree_polarity(child, max_depth-1, visited)\n",
    "            if p_child != 0.0:\n",
    "                return p_child, src\n",
    "\n",
    "    # Si no halló en hijos prioritarios, buscar entre todos los hijos\n",
    "    for child in token.children:\n",
    "        p_child, src = _search_subtree_polarity(child, max_depth-1, visited)\n",
    "        if p_child != 0.0:\n",
    "            return p_child, src\n",
    "\n",
    "    return 0.0, None\n",
    "\n",
    "def _has_negation_affecting(token):\n",
    "    \"\"\"\n",
    "    Detecta negación que afecte al token: puede estar en sus hijos (dep_='neg')\n",
    "    o en sus ancestros directos (p.ej. 'no' que modifica el verbo superior).\n",
    "    \"\"\"\n",
    "    # hijos con dep_ == neg\n",
    "    for ch in token.children:\n",
    "        if ch.dep_ == \"neg\" or ch.lemma_.lower() in {\"no\", \"nunca\", \"jamás\"}:\n",
    "            return True\n",
    "    # ancestros con negación (por ejemplo, la negación puede estar sobre el verbo principal)\n",
    "    for anc in token.ancestors:\n",
    "        for ch in anc.children:\n",
    "            if ch.dep_ == \"neg\" or ch.lemma_.lower() in {\"no\", \"nunca\", \"jamás\"}:\n",
    "                # si la negación está en un ancestro cercano, la consideramos\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def sentimiento_token(token):\n",
    "    \"\"\"\n",
    "    Calcula la polaridad asociada a este token de forma contextual:\n",
    "    - intenta obtener polaridad del propio token (por lema)\n",
    "    - si no la tiene, busca en su subtree (adjetivos que califican, complementos)\n",
    "    - aplica negación y modificadores (advmod)\n",
    "    - en caso de tokens que funcionan como determinantes/modificadores, consulta el head\n",
    "    \"\"\"\n",
    "    # 1) intentar polaridad directa\n",
    "    base = _lookup_lemma_polarity(token)\n",
    "\n",
    "    source_token = None\n",
    "    if base != 0.0:\n",
    "        source_token = token\n",
    "    else:\n",
    "        # 2) buscar en subtree (hijos que puedan portar polaridad)\n",
    "        base, source_token = _search_subtree_polarity(token, max_depth=2)\n",
    "\n",
    "    # 3) si todavía 0, intentar tomar la polaridad del head (ej: DET -> NOUN, o token dentro de frase)\n",
    "    if base == 0.0 and token.head is not None and token.head != token:\n",
    "        base = _lookup_lemma_polarity(token.head)\n",
    "        if base == 0.0:\n",
    "            # también buscar en subtree del head\n",
    "            base, source_token = _search_subtree_polarity(token.head, max_depth=1)\n",
    "\n",
    "    # Si no hay polaridad encontrada, devolvemos 0 (pero sin salir prematuramente)\n",
    "    if base == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    # 4) detectar y aplicar negación que afecte al token/palabra fuente\n",
    "    # chequeamos negación sobre el token original y sobre la fuente encontrada\n",
    "    neg = _has_negation_affecting(token)\n",
    "    if source_token is not None and not neg:\n",
    "        neg = _has_negation_affecting(source_token)\n",
    "    if neg:\n",
    "        base *= -1\n",
    "\n",
    "    # 5) aplicar modificadores (intensificadores/atenuadores) que sean hijos del source_token o del token\n",
    "    modifiers_sources = [token]\n",
    "    if source_token is not None and source_token != token:\n",
    "        modifiers_sources.append(source_token)\n",
    "\n",
    "    for src in modifiers_sources:\n",
    "        for ch in src.children:\n",
    "            if ch.dep_ == \"advmod\" or ch.pos_ == \"ADV\":\n",
    "                lemma = ch.lemma_.lower()\n",
    "                if lemma in intensificadores:\n",
    "                    base *= intensificadores[lemma]\n",
    "                elif lemma in atenuadores:\n",
    "                    base *= atenuadores[lemma]\n",
    "\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a52d7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_por_conjunciones(texto):\n",
    "    \"\"\"\n",
    "    Divide el texto en suboraciones según conjunciones adversativas (pero, aunque, sin embargo...).\n",
    "    \"\"\"\n",
    "    doc = nlp(texto)\n",
    "    suboraciones = []\n",
    "    start = 0\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.lower() in {\"pero\", \"aunque\", \"sin embargo\", \"sin embargo,\"}:\n",
    "            sub = doc[start:token.i].text.strip(\", \")\n",
    "            if sub:\n",
    "                suboraciones.append(sub)\n",
    "            start = token.i + 1\n",
    "\n",
    "    # agregar la última parte\n",
    "    final = doc[start:].text.strip(\", \")\n",
    "    if final:\n",
    "        suboraciones.append(final)\n",
    "\n",
    "    return suboraciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b5986b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_sentimiento(texto):\n",
    "    suboraciones = dividir_por_conjunciones(texto)\n",
    "    if not suboraciones:\n",
    "        suboraciones = [texto]\n",
    "\n",
    "    polaridades = []\n",
    "    for sub in suboraciones:\n",
    "        doc = nlp(sub)\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for token in doc:\n",
    "            p = sentimiento_token(token)\n",
    "            if p != 0:\n",
    "                total += p\n",
    "                count += 1\n",
    "        polaridad_media = total / count if count > 0 else 0\n",
    "        polaridades.append(polaridad_media)\n",
    "    \n",
    "    # Composición global del texto\n",
    "    if len(polaridades) > 0:\n",
    "        global_sentimiento = sum(polaridades) / len(polaridades)\n",
    "    else:\n",
    "        global_sentimiento = 0\n",
    "    \n",
    "    # Clasificación final\n",
    "    if global_sentimiento > 0.25:\n",
    "        etiqueta = \"Positivo\"\n",
    "    elif global_sentimiento < -0.25:\n",
    "        etiqueta = \"Negativo\"\n",
    "    else:\n",
    "        etiqueta = \"Neutro\"\n",
    "\n",
    "    return {\n",
    "        \"sentimiento_global\": round(global_sentimiento, 2),\n",
    "        \"etiqueta\": etiqueta,\n",
    "        \"detalles\": polaridades\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e3b11aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentimiento_global': -0.4, 'etiqueta': 'Negativo', 'detalles': [-0.8, 0]}\n"
     ]
    }
   ],
   "source": [
    "texto = \"No me gusta el servicio, pero la comida está muy buena.\"\n",
    "resultado = analizar_sentimiento(texto)\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931d150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentimiento_global': 0, 'etiqueta': 'Neutro', 'detalles': [0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# --- Diccionarios léxicos ---\n",
    "polaridad = {\n",
    "    \"bueno\": 1.0,\n",
    "    \"excelente\": 1.5,\n",
    "    \"positivo\": 1.0,\n",
    "    \"agradable\": 1.0,\n",
    "    \"malo\": -1.0,\n",
    "    \"terrible\": -1.5,\n",
    "    \"horrible\": -1.5,\n",
    "    \"deficiente\": -0.8,\n",
    "    \"gusta\": 0.8,\n",
    "    \"encanta\": 1.2,\n",
    "    \"odia\": -1.2,\n",
    "    \"mal\": -0.8,\n",
    "    \"feo\": -1.0,\n",
    "    \"bonito\": 0.8,\n",
    "    \"delicioso\": 1.3,\n",
    "    \"asqueroso\": -1.3\n",
    "}\n",
    "\n",
    "intensificadores = {\n",
    "    \"muy\": 1.5,\n",
    "    \"bastante\": 1.3,\n",
    "    \"poco\": 0.5,\n",
    "    \"algo\": 0.8\n",
    "}\n",
    "\n",
    "# --- 1. Dividir por conjunciones adversativas ---\n",
    "def dividir_por_conjunciones(texto):\n",
    "    doc = nlp(texto)\n",
    "    suboraciones = []\n",
    "    conjunciones = []\n",
    "    start = 0\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.lower() in {\"pero\", \"aunque\", \"sin embargo\"}:\n",
    "            sub = doc[start:token.i].text.strip(\", \")\n",
    "            if sub:\n",
    "                suboraciones.append(sub)\n",
    "                conjunciones.append(token.text.lower())\n",
    "            start = token.i + 1\n",
    "\n",
    "    final = doc[start:].text.strip(\", \")\n",
    "    if final:\n",
    "        suboraciones.append(final)\n",
    "\n",
    "    return suboraciones, conjunciones\n",
    "\n",
    "\n",
    "# --- 2. Analizar el sentimiento de un token ---\n",
    "def sentimiento_token(token):\n",
    "    # Polaridad base si existe\n",
    "    base = polaridad.get(token.lemma_, None)\n",
    "\n",
    "    # Si no hay polaridad léxica, no devolvemos nada todavía\n",
    "    if base is None:\n",
    "        return 0\n",
    "\n",
    "    # Negaciones\n",
    "    for hijo in token.children:\n",
    "        if hijo.dep_ == \"neg\" or hijo.lemma_ == \"no\":\n",
    "            base *= -1\n",
    "\n",
    "    # Intensificadores\n",
    "    for hijo in token.children:\n",
    "        if hijo.pos_ == \"ADV\" and hijo.lemma_ in intensificadores:\n",
    "            base *= intensificadores[hijo.lemma_]\n",
    "\n",
    "    # También si este token es modificado por un adverbio (e.g., “muy buena”)\n",
    "    for tok in token.head.children:\n",
    "        if tok.pos_ == \"ADV\" and tok.lemma_ in intensificadores and tok.head == token:\n",
    "            base *= intensificadores[tok.lemma_]\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "# --- 3. Combinar polaridades según conjunciones ---\n",
    "def combinar_polaridades(polaridades, conjunciones):\n",
    "    if not polaridades:\n",
    "        return 0\n",
    "\n",
    "    # Si hay \"pero\" o \"aunque\", priorizar la última parte\n",
    "    if any(c in {\"pero\", \"sin embargo\", \"aunque\"} for c in conjunciones):\n",
    "        return polaridades[-1]\n",
    "    else:\n",
    "        # promedio simple si no hay contraste\n",
    "        return sum(polaridades) / len(polaridades)\n",
    "\n",
    "\n",
    "# --- 4. Analizar sentimiento global ---\n",
    "def analizar_sentimiento(texto):\n",
    "    suboraciones, conjunciones = dividir_por_conjunciones(texto)\n",
    "    if not suboraciones:\n",
    "        suboraciones = [texto]\n",
    "\n",
    "    polaridades = []\n",
    "    for sub in suboraciones:\n",
    "        doc = nlp(sub)\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for token in doc:\n",
    "            p = sentimiento_token(token)\n",
    "            if p != 0:\n",
    "                total += p\n",
    "                count += 1\n",
    "        polaridad_media = total / count if count > 0 else 0\n",
    "        polaridades.append(polaridad_media)\n",
    "\n",
    "    polaridad_final = combinar_polaridades(polaridades, conjunciones)\n",
    "\n",
    "    etiqueta = (\n",
    "        \"Positivo\" if polaridad_final > 0.1 else\n",
    "        \"Negativo\" if polaridad_final < -0.1 else\n",
    "        \"Neutro\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"sentimiento_global\": round(polaridad_final, 2),\n",
    "        \"etiqueta\": etiqueta,\n",
    "        \"detalles\": [round(p, 2) for p in polaridades]\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Ejemplo ---\n",
    "texto = \"No me gusta el servicio, pero la comida está muy buena.\"\n",
    "resultado = analizar_sentimiento(texto)\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8256cf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentimiento_global': -0.8, 'etiqueta': 'Negativo', 'detalles_por_span': [[-0.8], [-0.8]], 'polaridades_spans': [-0.8, -0.8], 'conjunciones': ['pero']}\n"
     ]
    }
   ],
   "source": [
    "# --- Léxicos (lemmas en minúscula) ---\n",
    "polaridad = {\n",
    "    \"bueno\": 1.0, \"excelente\": 1.5, \"agradable\": 1.0,\n",
    "    \"malo\": -1.0, \"terrible\": -1.5, \"horrible\": -1.5,\n",
    "    \"deficiente\": -0.8, \"gustar\": 0.8, \"encantar\": 1.2,\n",
    "    \"odiar\": -1.2, \"mal\": -0.8, \"feo\": -1.0,\n",
    "    \"bonito\": 0.8, \"delicioso\": 1.3, \"asqueroso\": -1.3\n",
    "}\n",
    "\n",
    "intensificadores = {\"muy\": 1.5, \"bastante\": 1.3, \"sumamente\": 1.7}\n",
    "atenuadores = {\"poco\": 0.6, \"algo\": 0.8, \"un_poco\": 0.7}\n",
    "\n",
    "# Conectores adversativos y su peso para priorizar la cláusula posterior\n",
    "ADVERSATIVE_WEIGHTS = {\n",
    "    \"pero\": 0.7,\n",
    "    \"sin embargo\": 0.75,\n",
    "    \"aunque\": 0.6,\n",
    "    \"no obstante\": 0.7\n",
    "}\n",
    "\n",
    "# ---------- utilidades de búsqueda en árbol ----------\n",
    "def _lookup_polarity_by_lemma(token):\n",
    "    return polaridad.get(token.lemma_.lower(), 0.0)\n",
    "\n",
    "def _search_subtree_polarity(token, max_depth=2, visited=None):\n",
    "    \"\"\"\n",
    "    Busca polaridad en token y en hijos relevantes hasta max_depth.\n",
    "    Devuelve (p, source_token) donde p puede ser 0.0 si no halló.\n",
    "    \"\"\"\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    key = (token.i, token.sent.start)\n",
    "    if key in visited:\n",
    "        return 0.0, None\n",
    "    visited.add(key)\n",
    "\n",
    "    p = _lookup_polarity_by_lemma(token)\n",
    "    if abs(p) > 1e-9:\n",
    "        return p, token\n",
    "\n",
    "    if max_depth <= 0:\n",
    "        return 0.0, None\n",
    "\n",
    "    # hijos prioritarios\n",
    "    for child in token.children:\n",
    "        if child.dep_ in {\"amod\", \"advmod\", \"acomp\", \"xcomp\", \"ccomp\", \"obj\", \"iobj\"}:\n",
    "            p_child, src = _search_subtree_polarity(child, max_depth - 1, visited)\n",
    "            if abs(p_child) > 1e-9:\n",
    "                return p_child, src\n",
    "\n",
    "    # luego buscar más ampliamente entre hijos\n",
    "    for child in token.children:\n",
    "        p_child, src = _search_subtree_polarity(child, max_depth - 1, visited)\n",
    "        if abs(p_child) > 1e-9:\n",
    "            return p_child, src\n",
    "\n",
    "    return 0.0, None\n",
    "\n",
    "def _has_negation_affecting(token):\n",
    "    # busca 'neg' en hijos directos\n",
    "    for ch in token.children:\n",
    "        if ch.dep_ == \"neg\" or ch.lemma_.lower() in {\"no\", \"nunca\", \"jamás\"}:\n",
    "            return True\n",
    "    # busca negación en ancestros cercanos\n",
    "    for anc in token.ancestors:\n",
    "        for ch in anc.children:\n",
    "            if ch.dep_ == \"neg\" or ch.lemma_.lower() in {\"no\", \"nunca\", \"jamás\"}:\n",
    "                # si la negación está en ancestro cercano, la consideramos\n",
    "                # limitamos a ancestros cercanos: depth implícito por la naturaleza del árbol\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def _apply_modifiers(base, source_token, token):\n",
    "    \"\"\"\n",
    "    Aplica intensificadores/atenuadores encontrados como hijos del source_token o del token.\n",
    "    \"\"\"\n",
    "    if base == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # revisar hijos del source\n",
    "    for ch in list(source_token.children) + list(token.children):\n",
    "        if ch.pos_ == \"ADV\":\n",
    "            lemma = ch.lemma_.lower()\n",
    "            if lemma in intensificadores:\n",
    "                base *= intensificadores[lemma]\n",
    "            elif lemma in atenuadores:\n",
    "                base *= atenuadores[lemma]\n",
    "    # revisar adverbios que estén en el head (caso \"muy buena\" a veces estructura diferente)\n",
    "    for ch in source_token.head.children:\n",
    "        if ch.pos_ == \"ADV\" and ch.head == source_token:\n",
    "            lemma = ch.lemma_.lower()\n",
    "            if lemma in intensificadores:\n",
    "                base *= intensificadores[lemma]\n",
    "            elif lemma in atenuadores:\n",
    "                base *= atenuadores[lemma]\n",
    "\n",
    "    return base\n",
    "\n",
    "# ---------- análisis de una región/span ----------\n",
    "def sentimiento_para_span(span):\n",
    "    \"\"\"\n",
    "    Analiza un span (suboración) usando dependencia. \n",
    "    Busca fuentes de polaridad en el árbol y compone un valor medio.\n",
    "    \"\"\"\n",
    "    encontrados = {}  # source_token.i -> polaridad (evita duplicados)\n",
    "    for token in span:\n",
    "        # intentar encontrar polaridad en token o en su subtree/head\n",
    "        p, src = _search_subtree_polarity(token, max_depth=2)\n",
    "        if abs(p) < 1e-9:\n",
    "            # intentar en el head si no se encontró\n",
    "            if token.head is not None and token.head != token:\n",
    "                p, src = _search_subtree_polarity(token.head, max_depth=1)\n",
    "        if abs(p) < 1e-9:\n",
    "            continue\n",
    "\n",
    "        # aplicar negación relativa al token y al source\n",
    "        neg = _has_negation_affecting(token)\n",
    "        if src is not None and not neg:\n",
    "            neg = _has_negation_affecting(src)\n",
    "        if neg:\n",
    "            p *= -1\n",
    "\n",
    "        # aplicar modificadores\n",
    "        if src is None:\n",
    "            src = token\n",
    "        p = _apply_modifiers(p, src, token)\n",
    "\n",
    "        # almacenar (evitar contar mismo source dos veces)\n",
    "        if src.i not in encontrados:\n",
    "            encontrados[src.i] = p\n",
    "\n",
    "    if not encontrados:\n",
    "        return 0.0, []\n",
    "    vals = list(encontrados.values())\n",
    "    # retorno promedio simple de fuentes encontradas en este span\n",
    "    return sum(vals) / len(vals), vals\n",
    "\n",
    "# ---------- división por conjunciones (mejorada) ----------\n",
    "def dividir_por_conjunciones_doc(doc):\n",
    "    \"\"\"Divide el Doc en sub-spans por conjunciones adversativas detectadas.\"\"\"\n",
    "    adversatives = set(ADVERSATIVE_WEIGHTS.keys())\n",
    "    # buscar tokens que actúen como conectores\n",
    "    boundaries = []\n",
    "    for token in doc:\n",
    "        text_low = token.text.lower()\n",
    "        # tratar multi-word connectors (sin embargo) mirando token+next\n",
    "        two = (token.text + \" \" + (token.nbor(1).text if token.i+1 < len(doc) else \"\")).lower()\n",
    "        if text_low in adversatives:\n",
    "            boundaries.append((token.i, token.text.lower()))\n",
    "        elif two in adversatives:\n",
    "            boundaries.append((token.i, two))\n",
    "    # si no hay boundaries, return whole doc as one span\n",
    "    if not boundaries:\n",
    "        return [doc], []\n",
    "    spans = []\n",
    "    conj_vals = []\n",
    "    start = 0\n",
    "    for (idx, conj_text) in boundaries:\n",
    "        # span is doc[start: idx]\n",
    "        span = doc[start:idx]\n",
    "        if span.text.strip():\n",
    "            spans.append(span)\n",
    "            conj_vals.append(conj_text)\n",
    "        # move start to after connector token (one or two tokens)\n",
    "        if \" \" in conj_text:\n",
    "            start = idx + 2\n",
    "        else:\n",
    "            start = idx + 1\n",
    "    # last span\n",
    "    lastspan = doc[start: len(doc)]\n",
    "    if lastspan.text.strip():\n",
    "        spans.append(lastspan)\n",
    "    return spans, conj_vals\n",
    "\n",
    "# ---------- combinar polaridades con ponderación ----------\n",
    "def combinar_polaridades(polaridades, conjunciones):\n",
    "    if not polaridades:\n",
    "        return 0.0\n",
    "    if not conjunciones:\n",
    "        return sum(polaridades) / len(polaridades)\n",
    "    # si hay varios, aplicamos la regla local: cada conjuncion pondera la parte posterior\n",
    "    # asumimos que polaridades list está en orden y conjunciones apunta a las separaciones anteriores\n",
    "    # simplificamos: si hay al menos una conj adversativa, aplicamos peso a la última cláusula según el conector detectado\n",
    "    last_conj = conjunciones[-1]\n",
    "    weight_last = ADVERSATIVE_WEIGHTS.get(last_conj, 0.7)\n",
    "    # weight_last aplica a la última polaridad\n",
    "    if len(polaridades) == 1:\n",
    "        return polaridades[0]\n",
    "    # combinar: last * w + rest_mean * (1-w)\n",
    "    rest_mean = sum(polaridades[:-1]) / len(polaridades[:-1])\n",
    "    return polaridades[-1] * weight_last + rest_mean * (1 - weight_last)\n",
    "\n",
    "# ---------- función principal ----------\n",
    "def analizar_sentimiento(texto):\n",
    "    doc = nlp(texto)\n",
    "    spans, conjunciones = dividir_por_conjunciones_doc(doc)\n",
    "    polaridades = []\n",
    "    detalles = []\n",
    "    for span in spans:\n",
    "        p_span, fuentes = sentimiento_para_span(span)\n",
    "        polaridades.append(round(p_span, 4))\n",
    "        detalles.append([round(x,4) for x in fuentes])\n",
    "    p_final = combinar_polaridades(polaridades, conjunciones)\n",
    "    etiqueta = \"Positivo\" if p_final > 0.1 else (\"Negativo\" if p_final < -0.1 else \"Neutro\")\n",
    "    return {\n",
    "        \"sentimiento_global\": round(p_final, 4),\n",
    "        \"etiqueta\": etiqueta,\n",
    "        \"detalles_por_span\": detalles,\n",
    "        \"polaridades_spans\": polaridades,\n",
    "        \"conjunciones\": conjunciones\n",
    "    }\n",
    "\n",
    "# ---------- ejemplo ----------\n",
    "texto = \"No me gusta el servicio, pero la comida está muy buena.\"\n",
    "print(analizar_sentimiento(texto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4568df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- DICCIONARIO DE POLARIDAD ---\n",
    "polaridad = {\n",
    "    \"bueno\": 0.9,\n",
    "    \"excelente\": 1.0,\n",
    "    \"positivo\": 0.8,\n",
    "    \"agradable\": 0.7,\n",
    "    \"bonito\": 0.6,\n",
    "    \"malo\": -0.8,\n",
    "    \"terrible\": -1.0,\n",
    "    \"horrible\": -1.0,\n",
    "    \"negativo\": -0.7,\n",
    "    \"feo\": -0.6,\n",
    "    \"caro\": -0.4,\n",
    "    \"barato\": 0.5,\n",
    "    \"rápido\": 0.5,\n",
    "    \"lento\": -0.5,\n",
    "    \"satisfecho\": 0.8,\n",
    "    \"gusta\": 0.9,\n",
    "    \"gustar\": 0.9,\n",
    "    \"odio\": -1.0,\n",
    "    \"odiar\": -1.0,\n",
    "    \"encanta\": 1.0,\n",
    "    \"encantar\": 1.0,\n",
    "    \"mejor\": 0.8,\n",
    "    \"peor\": -0.8\n",
    "}\n",
    "\n",
    "# --- Normalización de adjetivos y formas ---\n",
    "def normalizar_lemma(lemma):\n",
    "    lemma = lemma.lower()\n",
    "    if lemma.endswith(\"a\") and lemma[:-1] + \"o\" in polaridad:\n",
    "        return lemma[:-1] + \"o\"\n",
    "    if lemma.endswith(\"as\") and lemma[:-2] + \"o\" in polaridad:\n",
    "        return lemma[:-2] + \"o\"\n",
    "    if lemma.endswith(\"os\") and lemma[:-2] + \"o\" in polaridad:\n",
    "        return lemma[:-2] + \"o\"\n",
    "    if lemma.endswith(\"es\") and lemma[:-2] in polaridad:\n",
    "        return lemma[:-2]\n",
    "    return lemma\n",
    "\n",
    "# --- Función de polaridad para un token individual ---\n",
    "def sentimiento_token(token):\n",
    "    lemma_norm = normalizar_lemma(token.lemma_)\n",
    "    base = polaridad.get(lemma_norm)\n",
    "    if base is None:\n",
    "        return 0\n",
    "\n",
    "    score = base\n",
    "\n",
    "    # --- NEGACIÓN ---\n",
    "    for child in token.children:\n",
    "        if child.dep_ == \"neg\":\n",
    "            score *= -1\n",
    "\n",
    "    # --- INTENSIFICADORES ---\n",
    "    for child in token.children:\n",
    "        if child.dep_ == \"advmod\":\n",
    "            if child.lemma_ in {\"muy\", \"bastante\", \"demasiado\"}:\n",
    "                score *= 1.5\n",
    "            elif child.lemma_ in {\"poco\"}:\n",
    "                score *= 0.5\n",
    "\n",
    "    return score\n",
    "\n",
    "# --- División por conjunciones adversativas ---\n",
    "def dividir_por_conjunciones(texto):\n",
    "    doc = nlp(texto)\n",
    "    suboraciones = []\n",
    "    start = 0\n",
    "    conjunciones = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() in {\"pero\", \"aunque\", \"sin embargo\"}:\n",
    "            sub = doc[start:token.i].text.strip(\", \")\n",
    "            if sub:\n",
    "                suboraciones.append(sub)\n",
    "            conjunciones.append(token.text.lower())\n",
    "            start = token.i + 1\n",
    "    final = doc[start:].text.strip(\", \")\n",
    "    if final:\n",
    "        suboraciones.append(final)\n",
    "    return suboraciones, conjunciones\n",
    "\n",
    "# --- Análisis de sentimiento completo ---\n",
    "def analizar_sentimiento(texto):\n",
    "    suboraciones, conjunciones = dividir_por_conjunciones(texto)\n",
    "    if not suboraciones:\n",
    "        suboraciones = [texto]\n",
    "\n",
    "    polaridades_spans = []\n",
    "    detalles_por_span = []\n",
    "\n",
    "    for sub in suboraciones:\n",
    "        doc = nlp(sub)\n",
    "        scores = []\n",
    "        for token in doc:\n",
    "            p = sentimiento_token(token)\n",
    "            if p != 0:\n",
    "                scores.append(p)\n",
    "        if scores:\n",
    "            polaridades_spans.append(sum(scores) / len(scores))\n",
    "        else:\n",
    "            polaridades_spans.append(0)\n",
    "        detalles_por_span.append(scores)\n",
    "\n",
    "    # --- Composición según conjunciones ---\n",
    "    if conjunciones:\n",
    "        if any(c in {\"pero\", \"sin embargo\"} for c in conjunciones):\n",
    "            sentimiento_global = polaridades_spans[-1]  # prioriza la última\n",
    "        elif \"aunque\" in conjunciones:\n",
    "            sentimiento_global = sum(polaridades_spans) / len(polaridades_spans)\n",
    "        else:\n",
    "            sentimiento_global = sum(polaridades_spans) / len(polaridades_spans)\n",
    "    else:\n",
    "        sentimiento_global = sum(polaridades_spans) / len(polaridades_spans)\n",
    "\n",
    "    if sentimiento_global > 0.1:\n",
    "        etiqueta = \"Positivo\"\n",
    "    elif sentimiento_global < -0.1:\n",
    "        etiqueta = \"Negativo\"\n",
    "    else:\n",
    "        etiqueta = \"Neutro\"\n",
    "\n",
    "    return {\n",
    "        \"sentimiento_global\": round(sentimiento_global, 2),\n",
    "        \"etiqueta\": etiqueta,\n",
    "        \"detalles_por_span\": detalles_por_span,\n",
    "        \"polaridades_spans\": polaridades_spans,\n",
    "        \"conjunciones\": conjunciones\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85180294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No me gusta el servicio, pero la comida está muy buena.\n",
      "{'sentimiento_global': 0, 'etiqueta': 'Neutro', 'detalles_por_span': [[0.9], []], 'polaridades_spans': [0.9, 0], 'conjunciones': ['pero']}\n",
      "\n",
      "El producto es caro aunque funciona bien.\n",
      "{'sentimiento_global': -0.2, 'etiqueta': 'Negativo', 'detalles_por_span': [[-0.4], []], 'polaridades_spans': [-0.4, 0], 'conjunciones': ['aunque']}\n",
      "\n",
      "El diseño es bonito y la batería dura mucho.\n",
      "{'sentimiento_global': 0.6, 'etiqueta': 'Positivo', 'detalles_por_span': [[0.6]], 'polaridades_spans': [0.6], 'conjunciones': []}\n",
      "\n",
      "No está nada mal el servicio.\n",
      "{'sentimiento_global': 0.0, 'etiqueta': 'Neutro', 'detalles_por_span': [[]], 'polaridades_spans': [0], 'conjunciones': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ej1 = \"No me gusta el servicio, pero la comida está muy buena.\"\n",
    "ej2 = \"El producto es caro aunque funciona bien.\"\n",
    "ej3 = \"El diseño es bonito y la batería dura mucho.\"\n",
    "ej4 = \"No está nada mal el servicio.\"\n",
    "ej5 = \"la comida está muy buena.\"\n",
    "\n",
    "\n",
    "for e in [ej1, ej2, ej3, ej4]:\n",
    "    print(e)\n",
    "    print(analizar_sentimiento(e))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
